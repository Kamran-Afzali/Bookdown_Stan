<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Gaussian Process Regression (GPR) | Stan Bookdown</title>
  <meta name="description" content="Chapter 8 Gaussian Process Regression (GPR) | Stan Bookdown" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Gaussian Process Regression (GPR) | Stan Bookdown" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Gaussian Process Regression (GPR) | Stan Bookdown" />
  
  
  

<meta name="author" content="Kamran Afzali" />


<meta name="date" content="2025-08-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayesian-multilevel-mixed-effects-regression-in-stan.html"/>
<link rel="next" href="bayesian-gaussian-mixture-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stan</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Choosing the Right Bayesian Model</a></li>
<li class="chapter" data-level="2" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html"><i class="fa fa-check"></i><b>2</b> Bayesian Modeling in R and Stan</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#what-is-stan"><i class="fa fa-check"></i><b>2.1</b> What is <code>stan</code>?</a></li>
<li class="chapter" data-level="2.2" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#model-file"><i class="fa fa-check"></i><b>2.2</b> Model file</a></li>
<li class="chapter" data-level="2.3" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#fit-the-model"><i class="fa fa-check"></i><b>2.3</b> Fit the model</a></li>
<li class="chapter" data-level="2.4" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#mcmc-diagnostics"><i class="fa fa-check"></i><b>2.4</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="2.5" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#conclusions"><i class="fa fa-check"></i><b>2.5</b> Conclusions</a></li>
<li class="chapter" data-level="2.6" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#references"><i class="fa fa-check"></i><b>2.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html"><i class="fa fa-check"></i><b>3</b> Bayesian Regression Models for Non-Normal Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#logistic-regression"><i class="fa fa-check"></i><b>3.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="3.2" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#negative-binomial"><i class="fa fa-check"></i><b>3.2</b> Negative Binomial</a></li>
<li class="chapter" data-level="3.3" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#conclusion"><i class="fa fa-check"></i><b>3.3</b> Conclusion</a></li>
<li class="chapter" data-level="3.4" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#references-1"><i class="fa fa-check"></i><b>3.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="robust-t-regression.html"><a href="robust-t-regression.html"><i class="fa fa-check"></i><b>4</b> Robust t-regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="robust-t-regression.html"><a href="robust-t-regression.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="robust-t-regression.html"><a href="robust-t-regression.html#concepts-and-code"><i class="fa fa-check"></i><b>4.2</b> Concepts and code</a></li>
<li class="chapter" data-level="4.3" data-path="robust-t-regression.html"><a href="robust-t-regression.html#conclusion-1"><i class="fa fa-check"></i><b>4.3</b> Conclusion</a></li>
<li class="chapter" data-level="4.4" data-path="robust-t-regression.html"><a href="robust-t-regression.html#references-2"><i class="fa fa-check"></i><b>4.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html"><i class="fa fa-check"></i><b>5</b> Bayesian Regularized Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#ridge-regression-and-gaussian-priors"><i class="fa fa-check"></i><b>5.2</b> Ridge Regression and Gaussian Priors</a></li>
<li class="chapter" data-level="5.3" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#lasso-regression-and-laplace-priors"><i class="fa fa-check"></i><b>5.3</b> LASSO Regression and Laplace Priors</a></li>
<li class="chapter" data-level="5.4" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#hierarchical-shrinkage-and-adaptive-priors"><i class="fa fa-check"></i><b>5.4</b> Hierarchical Shrinkage and Adaptive Priors</a></li>
<li class="chapter" data-level="5.5" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#implementation"><i class="fa fa-check"></i><b>5.5</b> Implementation</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#bayesian-ridge-regression"><i class="fa fa-check"></i><b>5.5.1</b> Bayesian Ridge Regression</a></li>
<li class="chapter" data-level="5.5.2" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#bayesian-lasso-regression"><i class="fa fa-check"></i><b>5.5.2</b> Bayesian LASSO Regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#hierarchical-shrinkage-horseshoe-prior"><i class="fa fa-check"></i><b>5.5.3</b> Hierarchical Shrinkage (Horseshoe Prior)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#empirical-comparison-and-model-evaluation"><i class="fa fa-check"></i><b>5.6</b> Empirical Comparison and Model Evaluation</a></li>
<li class="chapter" data-level="5.7" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#understanding-posterior-behavior"><i class="fa fa-check"></i><b>5.7</b> Understanding Posterior Behavior</a></li>
<li class="chapter" data-level="5.8" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#choosing-among-regularization-methods"><i class="fa fa-check"></i><b>5.8</b> Choosing Among Regularization Methods</a></li>
<li class="chapter" data-level="5.9" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#conclusion-2"><i class="fa fa-check"></i><b>5.9</b> Conclusion</a></li>
<li class="chapter" data-level="5.10" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#references-3"><i class="fa fa-check"></i><b>5.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html"><i class="fa fa-check"></i><b>6</b> Bayesian Quantile Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html#model-specification"><i class="fa fa-check"></i><b>6.1</b> Model Specification</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html#using-bayesqr-package"><i class="fa fa-check"></i><b>6.1.1</b> Using bayesQR package</a></li>
<li class="chapter" data-level="6.1.2" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html#using-brms-package"><i class="fa fa-check"></i><b>6.1.2</b> Using brms package</a></li>
<li class="chapter" data-level="6.1.3" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html#backend-stan-model"><i class="fa fa-check"></i><b>6.1.3</b> Backend stan model</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="bayesian-quantile-regression.html"><a href="bayesian-quantile-regression.html#references-4"><i class="fa fa-check"></i><b>6.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html"><i class="fa fa-check"></i><b>7</b> Bayesian Multilevel (Mixed Effects) Regression in Stan</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#multilevel-regression"><i class="fa fa-check"></i><b>7.2</b> Multilevel Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#bayesian-random-intercepts-model"><i class="fa fa-check"></i><b>7.2.1</b> Bayesian Random Intercepts Model</a></li>
<li class="chapter" data-level="7.2.2" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#bayesian-random-slopes-model"><i class="fa fa-check"></i><b>7.2.2</b> Bayesian Random Slopes Model</a></li>
<li class="chapter" data-level="7.2.3" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#hierarchical-priors-model"><i class="fa fa-check"></i><b>7.2.3</b> Hierarchical Priors Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#conclusion-3"><i class="fa fa-check"></i><b>7.3</b> Conclusion</a></li>
<li class="chapter" data-level="7.4" data-path="bayesian-multilevel-mixed-effects-regression-in-stan.html"><a href="bayesian-multilevel-mixed-effects-regression-in-stan.html#references-5"><i class="fa fa-check"></i><b>7.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html"><i class="fa fa-check"></i><b>8</b> Gaussian Process Regression (GPR)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html#introduction-3"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html#challenges"><i class="fa fa-check"></i><b>8.2</b> Challenges</a></li>
<li class="chapter" data-level="8.3" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html#gpfit-package"><i class="fa fa-check"></i><b>8.3</b> GPfit package</a></li>
<li class="chapter" data-level="8.4" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html#bayesian-stan"><i class="fa fa-check"></i><b>8.4</b> Bayesian Stan</a></li>
<li class="chapter" data-level="8.5" data-path="gaussian-process-regression-gpr.html"><a href="gaussian-process-regression-gpr.html#references-6"><i class="fa fa-check"></i><b>8.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayesian-gaussian-mixture-models.html"><a href="bayesian-gaussian-mixture-models.html"><i class="fa fa-check"></i><b>9</b> Bayesian Gaussian Mixture Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="bayesian-gaussian-mixture-models.html"><a href="bayesian-gaussian-mixture-models.html#single-varaible-example"><i class="fa fa-check"></i><b>9.1</b> Single varaible example</a></li>
<li class="chapter" data-level="9.2" data-path="bayesian-gaussian-mixture-models.html"><a href="bayesian-gaussian-mixture-models.html#example-with-multiple-variable"><i class="fa fa-check"></i><b>9.2</b> Example with multiple variable</a></li>
<li class="chapter" data-level="9.3" data-path="bayesian-gaussian-mixture-models.html"><a href="bayesian-gaussian-mixture-models.html#conclusion-4"><i class="fa fa-check"></i><b>9.3</b> Conclusion</a></li>
<li class="chapter" data-level="9.4" data-path="bayesian-gaussian-mixture-models.html"><a href="bayesian-gaussian-mixture-models.html#references-7"><i class="fa fa-check"></i><b>9.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html"><i class="fa fa-check"></i><b>10</b> Bayesian Canonical Correlation Analysis in Stan</a>
<ul>
<li class="chapter" data-level="10.1" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#introduction-4"><i class="fa fa-check"></i><b>10.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#canonical-correlation-analysis"><i class="fa fa-check"></i><b>10.1.1</b> Canonical Correlation Analysis</a></li>
<li class="chapter" data-level="10.1.2" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#stan-model"><i class="fa fa-check"></i><b>10.1.2</b> Stan Model</a></li>
<li class="chapter" data-level="10.1.3" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#model-validation-on-test-set"><i class="fa fa-check"></i><b>10.1.3</b> Model validation on test set</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#conclusion-5"><i class="fa fa-check"></i><b>10.2</b> Conclusion</a></li>
<li class="chapter" data-level="10.3" data-path="bayesian-canonical-correlation-analysis-in-stan.html"><a href="bayesian-canonical-correlation-analysis-in-stan.html#references-8"><i class="fa fa-check"></i><b>10.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><i class="fa fa-check"></i><b>11</b> Bayesian Seasonal Decomposition in Stan and RStan</a>
<ul>
<li class="chapter" data-level="11.1" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#simulating-seasonal-time-series-data"><i class="fa fa-check"></i><b>11.1</b> Simulating Seasonal Time Series Data*</a></li>
<li class="chapter" data-level="11.2" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#bayesian-seasonal-decomposition-model-in-stan"><i class="fa fa-check"></i><b>11.2</b> Bayesian Seasonal Decomposition Model in Stan</a></li>
<li class="chapter" data-level="11.3" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#fitting-the-model-in-r"><i class="fa fa-check"></i><b>11.3</b> Fitting the Model in R</a></li>
<li class="chapter" data-level="11.4" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#extracting-and-visualizing-components"><i class="fa fa-check"></i><b>11.4</b> Extracting and Visualizing Components</a></li>
<li class="chapter" data-level="11.5" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#extensions-and-applications"><i class="fa fa-check"></i><b>11.5</b> Extensions and Applications</a></li>
<li class="chapter" data-level="11.6" data-path="bayesian-seasonal-decomposition-in-stan-and-rstan.html"><a href="bayesian-seasonal-decomposition-in-stan-and-rstan.html#conclusion-6"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><i class="fa fa-check"></i><b>12</b> Bayesian Exponential Smoothing and Holt-Winters Models in Stan and RStan</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#bayesian-simple-exponential-smoothing-ses"><i class="fa fa-check"></i><b>12.1</b> Bayesian Simple Exponential Smoothing (SES)</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#stan-model-1"><i class="fa fa-check"></i><b>12.1.1</b> Stan Model</a></li>
<li class="chapter" data-level="12.1.2" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#fitting-in-r"><i class="fa fa-check"></i><b>12.1.2</b> Fitting in R</a></li>
<li class="chapter" data-level="12.1.3" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#visualization"><i class="fa fa-check"></i><b>12.1.3</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#bayesian-holt-winters-models"><i class="fa fa-check"></i><b>12.2</b> Bayesian Holt-Winters Models</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#without-seasonality-additive-trend"><i class="fa fa-check"></i><b>12.2.1</b> Without Seasonality (Additive Trend)</a></li>
<li class="chapter" data-level="12.2.2" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#stan-model-2"><i class="fa fa-check"></i><b>12.2.2</b> Stan Model</a></li>
<li class="chapter" data-level="12.2.3" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#visualization-1"><i class="fa fa-check"></i><b>12.2.3</b> Visualization</a></li>
<li class="chapter" data-level="12.2.4" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#with-seasonality-additive-seasonal-component"><i class="fa fa-check"></i><b>12.2.4</b> With Seasonality (Additive Seasonal Component)</a></li>
<li class="chapter" data-level="12.2.5" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#fit"><i class="fa fa-check"></i><b>12.2.5</b> Fit</a></li>
<li class="chapter" data-level="12.2.6" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#visualization-2"><i class="fa fa-check"></i><b>12.2.6</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html"><a href="bayesian-exponential-smoothing-and-holt-winters-models-in-stan-and-rstan.html#conclusion-7"><i class="fa fa-check"></i><b>12.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><a href="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><i class="fa fa-check"></i><b>13</b> Bayesian AR, ARMA, and ARIMA Models in Stan and RStan</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><a href="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html#bayesian-ar1-model"><i class="fa fa-check"></i><b>13.1</b> Bayesian AR(1) Model</a></li>
<li class="chapter" data-level="13.2" data-path="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><a href="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html#bayesian-arma11-model"><i class="fa fa-check"></i><b>13.2</b> Bayesian ARMA(1,1) Model</a></li>
<li class="chapter" data-level="13.3" data-path="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><a href="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html#bayesian-arima111-model"><i class="fa fa-check"></i><b>13.3</b> Bayesian ARIMA(1,1,1) Model</a></li>
<li class="chapter" data-level="13.4" data-path="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html"><a href="bayesian-ar-arma-and-arima-models-in-stan-and-rstan.html#conclusion-8"><i class="fa fa-check"></i><b>13.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html"><i class="fa fa-check"></i><b>14</b> 14 Bayesian Structural Time Series Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html#introduction-5"><i class="fa fa-check"></i><b>14.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html#stan-implementation-basic-bsts-model"><i class="fa fa-check"></i><b>14.1.1</b> Stan Implementation: Basic BSTS Model</a></li>
<li class="chapter" data-level="14.1.2" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html#stan-implementation-time-varying-trend-volatility"><i class="fa fa-check"></i><b>14.1.2</b> Stan Implementation: Time-Varying Trend Volatility</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html#model-comparison-and-selection"><i class="fa fa-check"></i><b>14.2</b> Model Comparison and Selection</a></li>
<li class="chapter" data-level="14.3" data-path="bayesian-structural-time-series-models.html"><a href="bayesian-structural-time-series-models.html#conclusion-9"><i class="fa fa-check"></i><b>14.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html"><i class="fa fa-check"></i><b>15</b> Model Comparison and Selection in Bayesian Analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#introduction-6"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>15.2</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="15.3" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#information-criteria-waic-and-loo-cv"><i class="fa fa-check"></i><b>15.3</b> Information Criteria: WAIC and LOO-CV</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#waic-watanabe-akaike-information-criterion"><i class="fa fa-check"></i><b>15.3.1</b> WAIC (Watanabe-Akaike Information Criterion)</a></li>
<li class="chapter" data-level="15.3.2" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#loo-cv-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>15.3.2</b> LOO-CV (Leave-One-Out Cross-Validation)</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#bayes-factors-vs.-information-criteria"><i class="fa fa-check"></i><b>15.4</b> Bayes Factors vs. Information Criteria</a></li>
<li class="chapter" data-level="15.5" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#summary-of-bayesian-model-comparison-methods"><i class="fa fa-check"></i><b>15.5</b> Summary of Bayesian Model Comparison Methods</a></li>
<li class="chapter" data-level="15.6" data-path="model-comparison-and-selection-in-bayesian-analysis.html"><a href="model-comparison-and-selection-in-bayesian-analysis.html#practical-example-comparing-models-in-r"><i class="fa fa-check"></i><b>15.6</b> Practical Example: Comparing Models in R</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>16</b> Appendix</a>
<ul>
<li class="chapter" data-level="16.1" data-path="appendix.html"><a href="appendix.html#main-stan-distributions-cheatsheet"><i class="fa fa-check"></i><b>16.1</b> Main Stan Distributions Cheatsheet</a></li>
<li class="chapter" data-level="16.2" data-path="appendix.html"><a href="appendix.html#main-stan-functions-cheatsheet"><i class="fa fa-check"></i><b>16.2</b> Main Stan Functions Cheatsheet</a></li>
<li class="chapter" data-level="16.3" data-path="appendix.html"><a href="appendix.html#why-non-distribution-functions"><i class="fa fa-check"></i><b>16.3</b> Why Non-Distribution Functions?</a></li>
<li class="chapter" data-level="16.4" data-path="appendix.html"><a href="appendix.html#stan-functions-cheatsheet"><i class="fa fa-check"></i><b>16.4</b> Stan Functions Cheatsheet</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="appendix.html"><a href="appendix.html#mathematical-functions"><i class="fa fa-check"></i><b>16.4.1</b> 1. Mathematical Functions</a></li>
<li class="chapter" data-level="16.4.2" data-path="appendix.html"><a href="appendix.html#transformation-functions"><i class="fa fa-check"></i><b>16.4.2</b> 2. Transformation Functions</a></li>
<li class="chapter" data-level="16.4.3" data-path="appendix.html"><a href="appendix.html#matrix-and-vector-operations"><i class="fa fa-check"></i><b>16.4.3</b> 3. Matrix and Vector Operations</a></li>
<li class="chapter" data-level="16.4.4" data-path="appendix.html"><a href="appendix.html#utility-functions"><i class="fa fa-check"></i><b>16.4.4</b> 4. Utility Functions</a></li>
<li class="chapter" data-level="16.4.5" data-path="appendix.html"><a href="appendix.html#specialized-solvers"><i class="fa fa-check"></i><b>16.4.5</b> 5. Specialized Solvers</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="appendix.html"><a href="appendix.html#example-hierarchical-linear-regression"><i class="fa fa-check"></i><b>16.5</b> Example: Hierarchical Linear Regression</a></li>
<li class="chapter" data-level="16.6" data-path="appendix.html"><a href="appendix.html#tips-for-using-stan-functions"><i class="fa fa-check"></i><b>16.6</b> Tips for Using Stan Functions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan Bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gaussian-process-regression-gpr" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Gaussian Process Regression (GPR)<a href="gaussian-process-regression-gpr.html#gaussian-process-regression-gpr" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-3" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Introduction<a href="gaussian-process-regression-gpr.html#introduction-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Gaussian process regression (GPR) is a machine learning method based on non-parametric regression method that can be used to fit arbitrary scalar and vectorial quantities. GPR provides a probabilistic model that can be used to make predictions and estimate the uncertainty of those predictions. A Gaussian process is a generalization of the Gaussian probability distribution to functions, where any finite set of function values has a joint Gaussian distribution. The mean function and covariance function of the Gaussian process describe the prior distribution of the function, and the observations are used to update the prior to the posterior distribution of the function. In GPR, the output variable is assumed to be a function of the input variables, and the function is modeled as a sample from a Gaussian process. The goal is to predict the value of the output variable at a new input point, given the observed data. The predicted value is given by the posterior mean of the Gaussian process, and the uncertainty of the prediction is given by the posterior variance. GPR is particularly useful when the data is noisy or when the function being modeled is complex and nonlinear. The key advantages of GPR over other regression techniques are its flexibility and its ability to provide a probabilistic framework for uncertainty quantification. GPR can be used for both regression and classification problems, and it can handle both scalar and vector-valued outputs. Moreover, GPR can be easily extended to handle non-stationary and non-Gaussian data. In practice, GPR is often implemented using the kernlab or gpflow packages in R or Python, respectively. These packages provide functions for specifying the kernel function, which is used to model the covariance between the input variables, and for estimating the hyperparameters of the kernel function using maximum likelihood or Bayesian methods.</p>
</div>
<div id="challenges" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Challenges<a href="gaussian-process-regression-gpr.html#challenges" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Overfitting occurs when a model is too complex and fits the training data too closely, resulting in poor generalization to new data. Like some other machine learning techniques, GPR is prone to overfitting if the model is too complex relative to the amount of data available. Specifically, if the number of hyperparameters of the Gaussian process model is large, or if the covariance function is too flexible, the model may fit the noise in the data rather than the underlying signal. This can result in poor generalization performance, where the model performs well on the training data but poorly on new, unseen data. To mitigate the risk of overfitting in GPR, it is important to carefully select the kernel function and the hyperparameters of the model based on the available data. Cross-validation can be used to estimate the generalization error of the model and to select the optimal values of the hyperparameters. Regularization techniques, such as adding a prior distribution on the hyperparameters or using Bayesian model selection, can also be used to prevent overfitting. Another way to prevent overfitting in GPR is to use a simpler covariance function that captures the key features of the data, rather than trying to fit the noise in the data. Overall, while GPR is a powerful and flexible regression technique, it requires careful tuning of the hyperparameters and selection of the kernel function to prevent overfitting and achieve good generalization performance.</p>
<p>GPR use in domains such as healthcare comes with certain challenges and limitations that should be considered. Computational complexity poses a significant challenge, particularly with large datasets, necessitating efficient algorithms and computational resources to handle the complexity. Hyperparameter tuning is another consideration, involving the selection of optimal values for parameters such as the kernel function and noise level. This task can be challenging and may require expert knowledge or extensive experimentation. Furthermore, as GPR models complex relationships, the interpretability of the learned models can become intricate. Understanding the underlying factors contributing to predictions becomes more challenging in highly nonlinear models. These challenges highlight the need for careful consideration and expertise when applying GPR in healthcare settings. GPRs ability to model complex relationships, estimate uncertainties, and provide interpretable predictions makes it an invaluable asset for predictive modeling in healthcare, with a postential to enhance disease progression modeling, personalize treatment plans, detect diseases early, and improve medical imaging analysis. While challenges exist, ongoing research and advancements in computational techniques are addressing these limitations, making GPR an increasingly valuable tool in healthcare. As the field continues to evolve, GPR is poised to revolutionize healthcare by enabling more accurate predictions, better decision-making, and improved patient outcomes.</p>
</div>
<div id="gpfit-package" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> GPfit package<a href="gaussian-process-regression-gpr.html#gpfit-package" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<pre><code># Load necessary packages
library(kernlab)
library(GPfit)
library(ggplot2)

# Generate simulated data
set.seed(123)
x &lt;- seq(0, 10, length = 50)
y &lt;- sin(x) + rnorm(50, 0, 0.2)
df &lt;- data.frame(x = x, y = y)

# Fit Gaussian process regression model
gpr_model &lt;- gausspr(y ~ x, data = df)
y_pred &lt;- predict(gpr_model, x)

# Visualize results
ggplot(df, aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = y_pred), color = &quot;red&quot;) +
  labs(title = &quot;Gaussian Process Regression&quot;, x = &quot;x&quot;, y = &quot;y&quot;)</code></pre>
<p>This R code performs Gaussian process regression (GPR) on simulated data and visualizes the results. Let’s break down each part of the code step-by-step:</p>
<ol style="list-style-type: decimal">
<li>Load Necessary Packages:</li>
</ol>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="gaussian-process-regression-gpr.html#cb110-1" tabindex="-1"></a><span class="fu">library</span>(kernlab)</span>
<span id="cb110-2"><a href="gaussian-process-regression-gpr.html#cb110-2" tabindex="-1"></a><span class="fu">library</span>(GPfit)</span>
<span id="cb110-3"><a href="gaussian-process-regression-gpr.html#cb110-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span></code></pre></div>
<p>This part loads the required R packages: <code>kernlab</code> for kernel-based machine learning, <code>GPfit</code> for Gaussian process modeling, and <code>ggplot2</code> for data visualization.</p>
<ol start="2" style="list-style-type: decimal">
<li>Generate Simulated Data:</li>
</ol>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="gaussian-process-regression-gpr.html#cb111-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb111-2"><a href="gaussian-process-regression-gpr.html#cb111-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">length =</span> <span class="dv">50</span>)</span>
<span id="cb111-3"><a href="gaussian-process-regression-gpr.html#cb111-3" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb111-4"><a href="gaussian-process-regression-gpr.html#cb111-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span></code></pre></div>
<p>Simulated data is generated for the predictor variable <code>x</code> and the response variable <code>y</code>. The <code>x</code> values are generated as a sequence from 0 to 10 with 50 points. The <code>y</code> values are generated by taking the sine of each <code>x</code> value and adding random noise from a normal distribution with mean 0 and standard deviation 0.2. The data is then combined into a data frame <code>df</code>.</p>
<ol start="3" style="list-style-type: decimal">
<li>Fit Gaussian Process Regression Model:</li>
</ol>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="gaussian-process-regression-gpr.html#cb112-1" tabindex="-1"></a>gpr_model <span class="ot">&lt;-</span> <span class="fu">gausspr</span>(y <span class="sc">~</span> x, <span class="at">data =</span> df)</span></code></pre></div>
<p>A Gaussian process regression model is fitted using the <code>gausspr</code> function from the <code>GPfit</code> package. The model specification is <code>y ~ x</code>, indicating that we want to model <code>y</code> as a function of <code>x</code> using Gaussian process regression.</p>
<ol start="4" style="list-style-type: decimal">
<li>Predict Values of y and Visualize Results:</li>
</ol>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="gaussian-process-regression-gpr.html#cb113-1" tabindex="-1"></a>y_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(gpr_model, x)</span>
<span id="cb113-2"><a href="gaussian-process-regression-gpr.html#cb113-2" tabindex="-1"></a></span>
<span id="cb113-3"><a href="gaussian-process-regression-gpr.html#cb113-3" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb113-4"><a href="gaussian-process-regression-gpr.html#cb113-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb113-5"><a href="gaussian-process-regression-gpr.html#cb113-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y_pred), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb113-6"><a href="gaussian-process-regression-gpr.html#cb113-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Gaussian Process Regression&quot;</span>, <span class="at">x =</span> <span class="st">&quot;x&quot;</span>, <span class="at">y =</span> <span class="st">&quot;y&quot;</span>)</span></code></pre></div>
<p>This part predicts the values of the response variable <code>y_pred</code> for the predictor variable <code>x</code> using the fitted Gaussian process regression model. The <code>predict</code> function is used to make the predictions based on the model <code>gpr_model</code>.</p>
<p>The results are then visualized using <code>ggplot2</code>. A scatter plot of the original data points (<code>x</code> and <code>y</code>) is created with blue points (<code>geom_point()</code>). Overlaid on the scatter plot is a red line representing the predictions of the response variable (<code>y_pred</code>) from the Gaussian process regression model (<code>geom_line(aes(y = y_pred), color = "red")</code>).</p>
</div>
<div id="bayesian-stan" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Bayesian Stan<a href="gaussian-process-regression-gpr.html#bayesian-stan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Gaussian process regression (GPR) can also be implemented in a Bayesian context using Stan. In Bayesian GPR, we assume a prior distribution for the unknown function and then update our beliefs about the function based on the observed data. The prior distribution is typically specified as a Gaussian process with a mean function and covariance function that depend on hyperparameters. The likelihood function for the observed data is also assumed to be Gaussian with a mean function equal to the prior mean function and a covariance function equal to the sum of the prior covariance function and a noise term. The hyperparameters of the prior and likelihood functions are estimated from the data using Markov chain Monte Carlo (MCMC) methods.</p>
<p>Here is an example of R code for fitting a Bayesian GPR model using Stan. Let’s break down each part of the code step-by-step:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="gaussian-process-regression-gpr.html#cb114-1" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb114-2"><a href="gaussian-process-regression-gpr.html#cb114-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb114-3"><a href="gaussian-process-regression-gpr.html#cb114-3" tabindex="-1"></a></span>
<span id="cb114-4"><a href="gaussian-process-regression-gpr.html#cb114-4" tabindex="-1"></a><span class="co"># Generate simulated data</span></span>
<span id="cb114-5"><a href="gaussian-process-regression-gpr.html#cb114-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb114-6"><a href="gaussian-process-regression-gpr.html#cb114-6" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">length =</span> <span class="dv">50</span>)</span>
<span id="cb114-7"><a href="gaussian-process-regression-gpr.html#cb114-7" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb114-8"><a href="gaussian-process-regression-gpr.html#cb114-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb114-9"><a href="gaussian-process-regression-gpr.html#cb114-9" tabindex="-1"></a></span>
<span id="cb114-10"><a href="gaussian-process-regression-gpr.html#cb114-10" tabindex="-1"></a><span class="co"># Stan model code</span></span>
<span id="cb114-11"><a href="gaussian-process-regression-gpr.html#cb114-11" tabindex="-1"></a>stan_model_code <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb114-12"><a href="gaussian-process-regression-gpr.html#cb114-12" tabindex="-1"></a><span class="st">functions {</span></span>
<span id="cb114-13"><a href="gaussian-process-regression-gpr.html#cb114-13" tabindex="-1"></a><span class="st">  vector gp_pred_rng(array[] real x2,</span></span>
<span id="cb114-14"><a href="gaussian-process-regression-gpr.html#cb114-14" tabindex="-1"></a><span class="st">                     vector y1,</span></span>
<span id="cb114-15"><a href="gaussian-process-regression-gpr.html#cb114-15" tabindex="-1"></a><span class="st">                     array[] real x1,</span></span>
<span id="cb114-16"><a href="gaussian-process-regression-gpr.html#cb114-16" tabindex="-1"></a><span class="st">                     real sigma_f,</span></span>
<span id="cb114-17"><a href="gaussian-process-regression-gpr.html#cb114-17" tabindex="-1"></a><span class="st">                     real lengthscale_f,</span></span>
<span id="cb114-18"><a href="gaussian-process-regression-gpr.html#cb114-18" tabindex="-1"></a><span class="st">                     real sigma,</span></span>
<span id="cb114-19"><a href="gaussian-process-regression-gpr.html#cb114-19" tabindex="-1"></a><span class="st">                     real jitter) {</span></span>
<span id="cb114-20"><a href="gaussian-process-regression-gpr.html#cb114-20" tabindex="-1"></a><span class="st">    int N1 = rows(y1);</span></span>
<span id="cb114-21"><a href="gaussian-process-regression-gpr.html#cb114-21" tabindex="-1"></a><span class="st">    int N2 = size(x2);</span></span>
<span id="cb114-22"><a href="gaussian-process-regression-gpr.html#cb114-22" tabindex="-1"></a><span class="st">    vector[N2] f2;</span></span>
<span id="cb114-23"><a href="gaussian-process-regression-gpr.html#cb114-23" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb114-24"><a href="gaussian-process-regression-gpr.html#cb114-24" tabindex="-1"></a><span class="st">      matrix[N1, N1] L_K;</span></span>
<span id="cb114-25"><a href="gaussian-process-regression-gpr.html#cb114-25" tabindex="-1"></a><span class="st">      vector[N1] K_div_y1;</span></span>
<span id="cb114-26"><a href="gaussian-process-regression-gpr.html#cb114-26" tabindex="-1"></a><span class="st">      matrix[N1, N2] k_x1_x2;</span></span>
<span id="cb114-27"><a href="gaussian-process-regression-gpr.html#cb114-27" tabindex="-1"></a><span class="st">      matrix[N1, N2] v_pred;</span></span>
<span id="cb114-28"><a href="gaussian-process-regression-gpr.html#cb114-28" tabindex="-1"></a><span class="st">      vector[N2] f2_mu;</span></span>
<span id="cb114-29"><a href="gaussian-process-regression-gpr.html#cb114-29" tabindex="-1"></a><span class="st">      matrix[N2, N2] cov_f2;</span></span>
<span id="cb114-30"><a href="gaussian-process-regression-gpr.html#cb114-30" tabindex="-1"></a><span class="st">      matrix[N1, N1] K;</span></span>
<span id="cb114-31"><a href="gaussian-process-regression-gpr.html#cb114-31" tabindex="-1"></a><span class="st">      K = gp_exp_quad_cov(x1, sigma_f, lengthscale_f);</span></span>
<span id="cb114-32"><a href="gaussian-process-regression-gpr.html#cb114-32" tabindex="-1"></a><span class="st">      for (n in 1:N1)</span></span>
<span id="cb114-33"><a href="gaussian-process-regression-gpr.html#cb114-33" tabindex="-1"></a><span class="st">        K[n, n] = K[n,n] + square(sigma);</span></span>
<span id="cb114-34"><a href="gaussian-process-regression-gpr.html#cb114-34" tabindex="-1"></a><span class="st">      L_K = cholesky_decompose(K);</span></span>
<span id="cb114-35"><a href="gaussian-process-regression-gpr.html#cb114-35" tabindex="-1"></a><span class="st">      K_div_y1 = mdivide_left_tri_low(L_K, y1);</span></span>
<span id="cb114-36"><a href="gaussian-process-regression-gpr.html#cb114-36" tabindex="-1"></a><span class="st">      K_div_y1 = mdivide_right_tri_low(K_div_y1&#39;, L_K)&#39;;</span></span>
<span id="cb114-37"><a href="gaussian-process-regression-gpr.html#cb114-37" tabindex="-1"></a><span class="st">      k_x1_x2 = gp_exp_quad_cov(x1, x2, sigma_f, lengthscale_f);</span></span>
<span id="cb114-38"><a href="gaussian-process-regression-gpr.html#cb114-38" tabindex="-1"></a><span class="st">      f2_mu = (k_x1_x2&#39; * K_div_y1);</span></span>
<span id="cb114-39"><a href="gaussian-process-regression-gpr.html#cb114-39" tabindex="-1"></a><span class="st">      v_pred = mdivide_left_tri_low(L_K, k_x1_x2);</span></span>
<span id="cb114-40"><a href="gaussian-process-regression-gpr.html#cb114-40" tabindex="-1"></a><span class="st">      cov_f2 = gp_exp_quad_cov(x2, sigma_f, lengthscale_f) - v_pred&#39; * v_pred;</span></span>
<span id="cb114-41"><a href="gaussian-process-regression-gpr.html#cb114-41" tabindex="-1"></a></span>
<span id="cb114-42"><a href="gaussian-process-regression-gpr.html#cb114-42" tabindex="-1"></a><span class="st">      f2 = multi_normal_rng(f2_mu, add_diag(cov_f2, rep_vector(jitter, N2)));</span></span>
<span id="cb114-43"><a href="gaussian-process-regression-gpr.html#cb114-43" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb114-44"><a href="gaussian-process-regression-gpr.html#cb114-44" tabindex="-1"></a><span class="st">    return f2;</span></span>
<span id="cb114-45"><a href="gaussian-process-regression-gpr.html#cb114-45" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb114-46"><a href="gaussian-process-regression-gpr.html#cb114-46" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-47"><a href="gaussian-process-regression-gpr.html#cb114-47" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb114-48"><a href="gaussian-process-regression-gpr.html#cb114-48" tabindex="-1"></a><span class="st">  int&lt;lower=1&gt; N;      // number of observations</span></span>
<span id="cb114-49"><a href="gaussian-process-regression-gpr.html#cb114-49" tabindex="-1"></a><span class="st">  vector[N] x;         // univariate covariate</span></span>
<span id="cb114-50"><a href="gaussian-process-regression-gpr.html#cb114-50" tabindex="-1"></a><span class="st">  vector[N] y;         // target variable</span></span>
<span id="cb114-51"><a href="gaussian-process-regression-gpr.html#cb114-51" tabindex="-1"></a><span class="st">  int&lt;lower=1&gt; N2;     // number of test points</span></span>
<span id="cb114-52"><a href="gaussian-process-regression-gpr.html#cb114-52" tabindex="-1"></a><span class="st">  vector[N2] x2;       // univariate test points</span></span>
<span id="cb114-53"><a href="gaussian-process-regression-gpr.html#cb114-53" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-54"><a href="gaussian-process-regression-gpr.html#cb114-54" tabindex="-1"></a><span class="st">transformed data {</span></span>
<span id="cb114-55"><a href="gaussian-process-regression-gpr.html#cb114-55" tabindex="-1"></a><span class="st">  // Normalize data</span></span>
<span id="cb114-56"><a href="gaussian-process-regression-gpr.html#cb114-56" tabindex="-1"></a><span class="st">  real xmean = mean(x);</span></span>
<span id="cb114-57"><a href="gaussian-process-regression-gpr.html#cb114-57" tabindex="-1"></a><span class="st">  real ymean = mean(y);</span></span>
<span id="cb114-58"><a href="gaussian-process-regression-gpr.html#cb114-58" tabindex="-1"></a><span class="st">  real xsd = sd(x);</span></span>
<span id="cb114-59"><a href="gaussian-process-regression-gpr.html#cb114-59" tabindex="-1"></a><span class="st">  real ysd = sd(y);</span></span>
<span id="cb114-60"><a href="gaussian-process-regression-gpr.html#cb114-60" tabindex="-1"></a><span class="st">  array[N] real xn = to_array_1d((x - xmean)/xsd);</span></span>
<span id="cb114-61"><a href="gaussian-process-regression-gpr.html#cb114-61" tabindex="-1"></a><span class="st">  array[N2] real x2n = to_array_1d((x2 - xmean)/xsd);</span></span>
<span id="cb114-62"><a href="gaussian-process-regression-gpr.html#cb114-62" tabindex="-1"></a><span class="st">  vector[N] yn = (y - ymean)/ysd;</span></span>
<span id="cb114-63"><a href="gaussian-process-regression-gpr.html#cb114-63" tabindex="-1"></a><span class="st">  real sigma_intercept = 1;</span></span>
<span id="cb114-64"><a href="gaussian-process-regression-gpr.html#cb114-64" tabindex="-1"></a><span class="st">  vector[N] zeros = rep_vector(0, N);</span></span>
<span id="cb114-65"><a href="gaussian-process-regression-gpr.html#cb114-65" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-66"><a href="gaussian-process-regression-gpr.html#cb114-66" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb114-67"><a href="gaussian-process-regression-gpr.html#cb114-67" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; lengthscale_f; // lengthscale of f</span></span>
<span id="cb114-68"><a href="gaussian-process-regression-gpr.html#cb114-68" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma_f;       // scale of f</span></span>
<span id="cb114-69"><a href="gaussian-process-regression-gpr.html#cb114-69" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigman;         // noise sigma</span></span>
<span id="cb114-70"><a href="gaussian-process-regression-gpr.html#cb114-70" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-71"><a href="gaussian-process-regression-gpr.html#cb114-71" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb114-72"><a href="gaussian-process-regression-gpr.html#cb114-72" tabindex="-1"></a><span class="st">  // covariances and Cholesky decompositions</span></span>
<span id="cb114-73"><a href="gaussian-process-regression-gpr.html#cb114-73" tabindex="-1"></a><span class="st">  matrix[N, N] K_f = gp_exp_quad_cov(xn, sigma_f, lengthscale_f)+</span></span>
<span id="cb114-74"><a href="gaussian-process-regression-gpr.html#cb114-74" tabindex="-1"></a><span class="st">                     sigma_intercept^2;</span></span>
<span id="cb114-75"><a href="gaussian-process-regression-gpr.html#cb114-75" tabindex="-1"></a><span class="st">  matrix[N, N] L_f = cholesky_decompose(add_diag(K_f, sigman^2));</span></span>
<span id="cb114-76"><a href="gaussian-process-regression-gpr.html#cb114-76" tabindex="-1"></a><span class="st">  // priors</span></span>
<span id="cb114-77"><a href="gaussian-process-regression-gpr.html#cb114-77" tabindex="-1"></a><span class="st">  lengthscale_f ~ normal(0, 1);</span></span>
<span id="cb114-78"><a href="gaussian-process-regression-gpr.html#cb114-78" tabindex="-1"></a><span class="st">  sigma_f ~ normal(0, 1);</span></span>
<span id="cb114-79"><a href="gaussian-process-regression-gpr.html#cb114-79" tabindex="-1"></a><span class="st">  sigman ~ normal(0, 1);</span></span>
<span id="cb114-80"><a href="gaussian-process-regression-gpr.html#cb114-80" tabindex="-1"></a><span class="st">  // model</span></span>
<span id="cb114-81"><a href="gaussian-process-regression-gpr.html#cb114-81" tabindex="-1"></a><span class="st">  yn ~ multi_normal_cholesky(zeros, L_f);</span></span>
<span id="cb114-82"><a href="gaussian-process-regression-gpr.html#cb114-82" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-83"><a href="gaussian-process-regression-gpr.html#cb114-83" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb114-84"><a href="gaussian-process-regression-gpr.html#cb114-84" tabindex="-1"></a><span class="st">  // function scaled back to the original scale</span></span>
<span id="cb114-85"><a href="gaussian-process-regression-gpr.html#cb114-85" tabindex="-1"></a><span class="st">  vector[N2] f = gp_pred_rng(x2n, yn, xn, sigma_f, lengthscale_f, sigman, 1e-9)*ysd + ymean;</span></span>
<span id="cb114-86"><a href="gaussian-process-regression-gpr.html#cb114-86" tabindex="-1"></a><span class="st">  real sigma = sigman*ysd;</span></span>
<span id="cb114-87"><a href="gaussian-process-regression-gpr.html#cb114-87" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb114-88"><a href="gaussian-process-regression-gpr.html#cb114-88" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb114-89"><a href="gaussian-process-regression-gpr.html#cb114-89" tabindex="-1"></a></span>
<span id="cb114-90"><a href="gaussian-process-regression-gpr.html#cb114-90" tabindex="-1"></a><span class="co"># Compile Stan model</span></span>
<span id="cb114-91"><a href="gaussian-process-regression-gpr.html#cb114-91" tabindex="-1"></a>gpr_stan_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> stan_model_code)</span>
<span id="cb114-92"><a href="gaussian-process-regression-gpr.html#cb114-92" tabindex="-1"></a></span>
<span id="cb114-93"><a href="gaussian-process-regression-gpr.html#cb114-93" tabindex="-1"></a><span class="co"># Prepare data for Stan model</span></span>
<span id="cb114-94"><a href="gaussian-process-regression-gpr.html#cb114-94" tabindex="-1"></a>stan_data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x=</span>df<span class="sc">$</span>x,</span>
<span id="cb114-95"><a href="gaussian-process-regression-gpr.html#cb114-95" tabindex="-1"></a>                  <span class="at">x2=</span>df<span class="sc">$</span>x,</span>
<span id="cb114-96"><a href="gaussian-process-regression-gpr.html#cb114-96" tabindex="-1"></a>                  <span class="at">y=</span>df<span class="sc">$</span>y,</span>
<span id="cb114-97"><a href="gaussian-process-regression-gpr.html#cb114-97" tabindex="-1"></a>                  <span class="at">N=</span><span class="fu">length</span>(df<span class="sc">$</span>x),</span>
<span id="cb114-98"><a href="gaussian-process-regression-gpr.html#cb114-98" tabindex="-1"></a>                  <span class="at">N2=</span><span class="fu">length</span>(df<span class="sc">$</span>x))</span>
<span id="cb114-99"><a href="gaussian-process-regression-gpr.html#cb114-99" tabindex="-1"></a></span>
<span id="cb114-100"><a href="gaussian-process-regression-gpr.html#cb114-100" tabindex="-1"></a><span class="co"># Fit Bayesian GPR model using Stan</span></span>
<span id="cb114-101"><a href="gaussian-process-regression-gpr.html#cb114-101" tabindex="-1"></a>gpr_fit <span class="ot">&lt;-</span> <span class="fu">sampling</span>(gpr_stan_model, <span class="at">data =</span> stan_data)</span>
<span id="cb114-102"><a href="gaussian-process-regression-gpr.html#cb114-102" tabindex="-1"></a></span>
<span id="cb114-103"><a href="gaussian-process-regression-gpr.html#cb114-103" tabindex="-1"></a></span>
<span id="cb114-104"><a href="gaussian-process-regression-gpr.html#cb114-104" tabindex="-1"></a>f_samples <span class="ot">&lt;-</span> <span class="fu">extract</span>(gpr_fit, <span class="st">&quot;f&quot;</span>)<span class="sc">$</span>f</span>
<span id="cb114-105"><a href="gaussian-process-regression-gpr.html#cb114-105" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">extract</span>(gpr_fit, <span class="st">&quot;sigma&quot;</span>)<span class="sc">$</span>sigma</span>
<span id="cb114-106"><a href="gaussian-process-regression-gpr.html#cb114-106" tabindex="-1"></a></span>
<span id="cb114-107"><a href="gaussian-process-regression-gpr.html#cb114-107" tabindex="-1"></a></span>
<span id="cb114-108"><a href="gaussian-process-regression-gpr.html#cb114-108" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb114-109"><a href="gaussian-process-regression-gpr.html#cb114-109" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Ef=</span><span class="fu">colMeans</span>(f_samples),</span>
<span id="cb114-110"><a href="gaussian-process-regression-gpr.html#cb114-110" tabindex="-1"></a>         <span class="at">sigma=</span><span class="fu">mean</span>(sigma_samples)) <span class="sc">%&gt;%</span>  </span>
<span id="cb114-111"><a href="gaussian-process-regression-gpr.html#cb114-111" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb114-112"><a href="gaussian-process-regression-gpr.html#cb114-112" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb114-113"><a href="gaussian-process-regression-gpr.html#cb114-113" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Time (ms)&quot;</span>, <span class="at">y=</span><span class="st">&quot;Acceleration (g)&quot;</span>)<span class="sc">+</span></span>
<span id="cb114-114"><a href="gaussian-process-regression-gpr.html#cb114-114" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef), <span class="at">color=</span><span class="st">&#39;red&#39;</span>)<span class="sc">+</span></span>
<span id="cb114-115"><a href="gaussian-process-regression-gpr.html#cb114-115" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef<span class="dv">-2</span><span class="sc">*</span>sigma), <span class="at">color=</span><span class="st">&#39;red&#39;</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb114-116"><a href="gaussian-process-regression-gpr.html#cb114-116" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>sigma), <span class="at">color=</span><span class="st">&#39;red&#39;</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li>Generate Simulated Data:</li>
</ol>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="gaussian-process-regression-gpr.html#cb115-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb115-2"><a href="gaussian-process-regression-gpr.html#cb115-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">length =</span> <span class="dv">50</span>)</span>
<span id="cb115-3"><a href="gaussian-process-regression-gpr.html#cb115-3" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb115-4"><a href="gaussian-process-regression-gpr.html#cb115-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span></code></pre></div>
<p>Simulated data is generated for the predictor variable <code>x</code> and the response variable <code>y</code>. The <code>x</code> values are generated as a sequence from 0 to 10 with 50 points. The <code>y</code> values are generated by taking the sine of each <code>x</code> value and adding random noise from a normal distribution with mean 0 and standard deviation 0.2. The data is then combined into a data frame <code>df</code>.</p>
<ol start="2" style="list-style-type: decimal">
<li>Specify Stan Model Code:</li>
</ol>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="gaussian-process-regression-gpr.html#cb116-1" tabindex="-1"></a>stan_model_code <span class="ot">&lt;-</span> <span class="st">&quot; ... &quot;</span></span></code></pre></div>
<p>The Stan model code is specified as a character string. The model defines the data, parameters, and the statistical model for Bayesian GPR. It uses a Gaussian process kernel to model the relationship between the predictor variable <code>x</code> and the response variable <code>y</code>. The parameters <code>mu</code>, <code>sigma_f</code>, <code>sigma_n</code>, and <code>eta</code> represent the mean function, the covariance function for the underlying Gaussian process, the noise standard deviation, and the latent function values, respectively.</p>
<ol start="3" style="list-style-type: decimal">
<li>Compile Stan Model:</li>
</ol>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="gaussian-process-regression-gpr.html#cb117-1" tabindex="-1"></a>gpr_stan_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> stan_model_code)</span></code></pre></div>
<p>The Stan model is compiled using the <code>stan_model</code> function from the <code>rstan</code> package. This step converts the Stan model code into a C++ program that will be used for Bayesian inference.</p>
<ol start="4" style="list-style-type: decimal">
<li>Prepare Data for Stan Model:</li>
</ol>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="gaussian-process-regression-gpr.html#cb118-1" tabindex="-1"></a>stan_data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x=</span>df<span class="sc">$</span>x,</span>
<span id="cb118-2"><a href="gaussian-process-regression-gpr.html#cb118-2" tabindex="-1"></a>                  <span class="at">x2=</span>df<span class="sc">$</span>x,</span>
<span id="cb118-3"><a href="gaussian-process-regression-gpr.html#cb118-3" tabindex="-1"></a>                  <span class="at">y=</span>df<span class="sc">$</span>y,</span>
<span id="cb118-4"><a href="gaussian-process-regression-gpr.html#cb118-4" tabindex="-1"></a>                  <span class="at">N=</span><span class="fu">length</span>(df<span class="sc">$</span>x),</span>
<span id="cb118-5"><a href="gaussian-process-regression-gpr.html#cb118-5" tabindex="-1"></a>                  <span class="at">N2=</span><span class="fu">length</span>(df<span class="sc">$</span>x))</span></code></pre></div>
<p>The data is prepared as a list <code>stan_data</code> with the number of rows <code>N</code>, the predictor variable <code>x</code>, and the response variable <code>y</code>. This data will be used as input to the Stan model during sampling.</p>
<ol start="5" style="list-style-type: decimal">
<li>Fit Bayesian GPR Model using Stan:</li>
</ol>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="gaussian-process-regression-gpr.html#cb119-1" tabindex="-1"></a>gpr_fit <span class="ot">&lt;-</span> <span class="fu">sampling</span>(gpr_stan_model, <span class="at">data =</span> stan_data)</span></code></pre></div>
<p>The Bayesian GPR model is fitted using the <code>sampling</code> function from <code>rstan</code>. This step performs Markov chain Monte Carlo (MCMC) sampling to estimate the posterior distribution of the model parameters.</p>
<ol start="6" style="list-style-type: decimal">
<li>Extract Posterior Samples of f for Prediction:</li>
</ol>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="gaussian-process-regression-gpr.html#cb120-1" tabindex="-1"></a>f_samples <span class="ot">&lt;-</span> <span class="fu">extract</span>(gpr_fit, <span class="st">&quot;f&quot;</span>)<span class="sc">$</span>f</span>
<span id="cb120-2"><a href="gaussian-process-regression-gpr.html#cb120-2" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">extract</span>(gpr_fit, <span class="st">&quot;sigma&quot;</span>)<span class="sc">$</span>sigma</span>
<span id="cb120-3"><a href="gaussian-process-regression-gpr.html#cb120-3" tabindex="-1"></a></span>
<span id="cb120-4"><a href="gaussian-process-regression-gpr.html#cb120-4" tabindex="-1"></a></span>
<span id="cb120-5"><a href="gaussian-process-regression-gpr.html#cb120-5" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb120-6"><a href="gaussian-process-regression-gpr.html#cb120-6" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Ef=</span><span class="fu">colMeans</span>(f_samples),</span>
<span id="cb120-7"><a href="gaussian-process-regression-gpr.html#cb120-7" tabindex="-1"></a>         <span class="at">sigma=</span><span class="fu">mean</span>(sigma_samples)) <span class="sc">%&gt;%</span>  </span>
<span id="cb120-8"><a href="gaussian-process-regression-gpr.html#cb120-8" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y))<span class="sc">+</span></span>
<span id="cb120-9"><a href="gaussian-process-regression-gpr.html#cb120-9" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb120-10"><a href="gaussian-process-regression-gpr.html#cb120-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Time (ms)&quot;</span>, <span class="at">y=</span><span class="st">&quot;Acceleration (g)&quot;</span>)<span class="sc">+</span></span>
<span id="cb120-11"><a href="gaussian-process-regression-gpr.html#cb120-11" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef), <span class="at">color=</span><span class="st">&#39;red&#39;</span>)<span class="sc">+</span></span>
<span id="cb120-12"><a href="gaussian-process-regression-gpr.html#cb120-12" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef<span class="dv">-2</span><span class="sc">*</span>sigma), <span class="at">color=</span><span class="st">&#39;red&#39;</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb120-13"><a href="gaussian-process-regression-gpr.html#cb120-13" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>Ef<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>sigma), <span class="at">color=</span><span class="st">&#39;red&#39;</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p>The <code>extract</code> function is used to extract the posterior samples of the latent function <code>f</code> from the fitted GPR model. These samples will be used to predict new values of <code>f</code> for new values of <code>x</code>.</p>
</div>
<div id="references-6" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> References<a href="gaussian-process-regression-gpr.html#references-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Duvenaud, D. K., Nickisch, H., &amp; Rasmussen, C. E. (2013). Gaussian processes for machine learning: tutorial. In S. Sra, S. Nowozin, &amp; S. J. Wright (Eds.), Optimization for Machine Learning (pp. 133-181). MIT Press.</li>
<li>Nguyen, T. D., &amp; Nguyen, T. T. (2018). Multi-task Gaussian process models for biomedical applications. arXiv preprint arXiv:1806.03836.</li>
<li>Alaa, A. M., &amp; van der Schaar, M. (2018). Prognostication and risk factors for cystic fibrosis via automated machine learning and Gaussian process regression. Scientific Reports, 8(1), 1-12.</li>
<li>Nguyen, T. T., Nguyen, H. T., Nguyen, T. L., &amp; Chetty, G. (2017). Gaussian process regression for predicting 30-day readmission of heart failure patients. Journal of Biomedical Informatics, 71, 199-209.</li>
<li>Kazemi, S., &amp; Soltanian-Zadeh, H. (2013). A new Gaussian process regression-based method for segmentation of brain tissues from MRI. Medical Image Analysis, 17(3), 225-234.</li>
<li><a href="https://avehtari.github.io/casestudies/Motorcycle/motorcycle_gpcourse.html">Gaussian process demonstration with Stan</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-multilevel-mixed-effects-regression-in-stan.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian-gaussian-mixture-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_Stan/edit/main/08-GPR.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_Stan/blob/main/08-GPR.Rmd",
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
