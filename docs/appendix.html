<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Appendix | Stan Bookdown</title>
  <meta name="description" content="Chapter 6 Appendix | Stan Bookdown" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Appendix | Stan Bookdown" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Appendix | Stan Bookdown" />
  
  
  

<meta name="author" content="Kamran Afzali" />


<meta name="date" content="2025-06-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayesian-regularized-regression.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stan</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Choosing the Right Bayesian Model</a></li>
<li class="chapter" data-level="2" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html"><i class="fa fa-check"></i><b>2</b> Bayesian Modeling in R and Stan</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#what-is-stan"><i class="fa fa-check"></i><b>2.1</b> What is STAN?</a></li>
<li class="chapter" data-level="2.2" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#model-file"><i class="fa fa-check"></i><b>2.2</b> Model file</a></li>
<li class="chapter" data-level="2.3" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#fit-the-model"><i class="fa fa-check"></i><b>2.3</b> Fit the model</a></li>
<li class="chapter" data-level="2.4" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#mcmc-diagnostics"><i class="fa fa-check"></i><b>2.4</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="2.5" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#parting-thoughts"><i class="fa fa-check"></i><b>2.5</b> Parting thoughts</a></li>
<li class="chapter" data-level="2.6" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#conclusions"><i class="fa fa-check"></i><b>2.6</b> Conclusions</a></li>
<li class="chapter" data-level="2.7" data-path="bayesian-modeling-in-r-and-stan.html"><a href="bayesian-modeling-in-r-and-stan.html#references"><i class="fa fa-check"></i><b>2.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html"><i class="fa fa-check"></i><b>3</b> Bayesian Regression Models for Non-Normal Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#logistic-regression"><i class="fa fa-check"></i><b>3.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="3.2" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#negative-binomial"><i class="fa fa-check"></i><b>3.2</b> Negative Binomial</a></li>
<li class="chapter" data-level="3.3" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#conclusion"><i class="fa fa-check"></i><b>3.3</b> Conclusion</a></li>
<li class="chapter" data-level="3.4" data-path="bayesian-regression-models-for-non-normal-data.html"><a href="bayesian-regression-models-for-non-normal-data.html#references-1"><i class="fa fa-check"></i><b>3.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="robust-t-regression.html"><a href="robust-t-regression.html"><i class="fa fa-check"></i><b>4</b> Robust t-regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="robust-t-regression.html"><a href="robust-t-regression.html#motivation"><i class="fa fa-check"></i><b>4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2" data-path="robust-t-regression.html"><a href="robust-t-regression.html#concepts-and-code"><i class="fa fa-check"></i><b>4.2</b> Concepts and code</a></li>
<li class="chapter" data-level="4.3" data-path="robust-t-regression.html"><a href="robust-t-regression.html#conclusion-1"><i class="fa fa-check"></i><b>4.3</b> Conclusion</a></li>
<li class="chapter" data-level="4.4" data-path="robust-t-regression.html"><a href="robust-t-regression.html#references-2"><i class="fa fa-check"></i><b>4.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html"><i class="fa fa-check"></i><b>5</b> Bayesian Regularized Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#regularized-regression"><i class="fa fa-check"></i><b>5.2</b> Regularized Regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#bayesian-ridge-regression"><i class="fa fa-check"></i><b>5.2.1</b> Bayesian Ridge Regression</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#bayesian-lasso-regression"><i class="fa fa-check"></i><b>5.2.2</b> Bayesian LASSO Regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#hierarchical-shrinkage"><i class="fa fa-check"></i><b>5.2.3</b> Hierarchical shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#conclusion-2"><i class="fa fa-check"></i><b>5.3</b> Conclusion</a></li>
<li class="chapter" data-level="5.4" data-path="bayesian-regularized-regression.html"><a href="bayesian-regularized-regression.html#references-3"><i class="fa fa-check"></i><b>5.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>6</b> Appendix</a>
<ul>
<li class="chapter" data-level="6.1" data-path="appendix.html"><a href="appendix.html#main-stan-distributions-cheatsheet"><i class="fa fa-check"></i><b>6.1</b> Main Stan Distributions Cheatsheet</a></li>
<li class="chapter" data-level="6.2" data-path="appendix.html"><a href="appendix.html#main-stan-functions-cheatsheet"><i class="fa fa-check"></i><b>6.2</b> Main Stan Functions Cheatsheet</a></li>
<li class="chapter" data-level="6.3" data-path="appendix.html"><a href="appendix.html#why-non-distribution-functions"><i class="fa fa-check"></i><b>6.3</b> Why Non-Distribution Functions?</a></li>
<li class="chapter" data-level="6.4" data-path="appendix.html"><a href="appendix.html#stan-functions-cheatsheet"><i class="fa fa-check"></i><b>6.4</b> Stan Functions Cheatsheet</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="appendix.html"><a href="appendix.html#mathematical-functions"><i class="fa fa-check"></i><b>6.4.1</b> 1. Mathematical Functions</a></li>
<li class="chapter" data-level="6.4.2" data-path="appendix.html"><a href="appendix.html#transformation-functions"><i class="fa fa-check"></i><b>6.4.2</b> 2. Transformation Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="appendix.html"><a href="appendix.html#matrix-and-vector-operations"><i class="fa fa-check"></i><b>6.4.3</b> 3. Matrix and Vector Operations</a></li>
<li class="chapter" data-level="6.4.4" data-path="appendix.html"><a href="appendix.html#utility-functions"><i class="fa fa-check"></i><b>6.4.4</b> 4. Utility Functions</a></li>
<li class="chapter" data-level="6.4.5" data-path="appendix.html"><a href="appendix.html#specialized-solvers"><i class="fa fa-check"></i><b>6.4.5</b> 5. Specialized Solvers</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="appendix.html"><a href="appendix.html#example-hierarchical-linear-regression"><i class="fa fa-check"></i><b>6.5</b> Example: Hierarchical Linear Regression</a></li>
<li class="chapter" data-level="6.6" data-path="appendix.html"><a href="appendix.html#tips-for-using-stan-functions"><i class="fa fa-check"></i><b>6.6</b> Tips for Using Stan Functions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stan Bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Appendix<a href="appendix.html#appendix" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="main-stan-distributions-cheatsheet" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Main Stan Distributions Cheatsheet<a href="appendix.html#main-stan-distributions-cheatsheet" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Statistical modeling in <strong>Stan</strong> is powered by a flexible and expressive probabilistic language grounded in <strong>log-density functions</strong>. While the modeling blocks (<code>model</code>, <code>data</code>, <code>parameters</code>, etc.) help structure a model, the core statistical logic is defined through <strong>distributions</strong>. This cheatsheet offers a practical summary of the most important distributions used in Stan, their syntax, required parameters, typical use cases, and examples of where they show up in statistical modeling.</p>
<hr />
<table>
<colgroup>
<col width="10%" />
<col width="14%" />
<col width="7%" />
<col width="19%" />
<col width="19%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Distribution</strong></th>
<th><strong>Function</strong></th>
<th><strong>Parameters</strong></th>
<th><strong>Use Case</strong></th>
<th><strong>Model Type(s)</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bernoulli</strong></td>
<td>`bernoulli_lpmf(y</td>
<td>θ)`</td>
<td><code>θ ∈ (0, 1)</code></td>
<td>Binary outcome (0/1)</td>
<td>Logistic regression, classification</td>
</tr>
<tr class="even">
<td><strong>Binomial</strong></td>
<td>`binomial_lpmf(y</td>
<td>n, θ)`</td>
<td><code>n ∈ ℕ⁺</code>, <code>θ ∈ (0, 1)</code></td>
<td># of successes in <code>n</code> trials</td>
<td>Logistic GLMs, grouped binomial models</td>
</tr>
<tr class="odd">
<td><strong>Categorical</strong></td>
<td>`categorical_lpmf(y</td>
<td>θ)`</td>
<td><code>θ</code>: simplex vector (length K)</td>
<td>Single draw from K categories</td>
<td>Multinomial regression</td>
</tr>
<tr class="even">
<td><strong>Multinomial</strong></td>
<td>`multinomial_lpmf(y</td>
<td>θ)`</td>
<td><code>y</code>: int vector of counts, <code>θ</code>: simplex</td>
<td>Category count data</td>
<td>Count models with category splits</td>
</tr>
<tr class="odd">
<td><strong>Normal</strong></td>
<td>`normal_lpdf(y</td>
<td>μ, σ)`</td>
<td><code>μ ∈ ℝ</code>, <code>σ &gt; 0</code></td>
<td>Gaussian noise, residuals</td>
<td>Linear regression, priors for real parameters</td>
</tr>
<tr class="even">
<td><strong>Student’s t</strong></td>
<td>`student_t_lpdf(y</td>
<td>ν, μ, σ)`</td>
<td><code>ν &gt; 0</code>, <code>μ ∈ ℝ</code>, <code>σ &gt; 0</code></td>
<td>Heavy-tailed data, robust models</td>
<td>Robust regression, hierarchical priors</td>
</tr>
<tr class="odd">
<td><strong>Cauchy</strong></td>
<td>`cauchy_lpdf(y</td>
<td>μ, σ)`</td>
<td><code>μ ∈ ℝ</code>, <code>σ &gt; 0</code></td>
<td>Weakly informative, heavy-tailed prior</td>
<td>Priors on scale parameters (e.g., <code>τ ~ cauchy(0, 2.5)</code>)</td>
</tr>
<tr class="even">
<td><strong>Exponential</strong></td>
<td>`exponential_lpdf(y</td>
<td>λ)`</td>
<td><code>λ &gt; 0</code></td>
<td>Time to event, memoryless processes</td>
<td>Survival models, Poisson process modeling</td>
</tr>
<tr class="odd">
<td><strong>Gamma</strong></td>
<td>`gamma_lpdf(y</td>
<td>α, β)`</td>
<td><code>α &gt; 0</code>, <code>β &gt; 0</code></td>
<td>Positive skewed data</td>
<td>Priors on rates or shape parameters</td>
</tr>
<tr class="even">
<td><strong>Inverse Gamma</strong></td>
<td>`inv_gamma_lpdf(y</td>
<td>α, β)`</td>
<td><code>α &gt; 0</code>, <code>β &gt; 0</code></td>
<td>Prior for variances</td>
<td>Priors on <code>σ²</code>, <code>τ²</code>, especially in hierarchies</td>
</tr>
<tr class="odd">
<td><strong>Lognormal</strong></td>
<td>`lognormal_lpdf(y</td>
<td>μ, σ)`</td>
<td><code>μ ∈ ℝ</code>, <code>σ &gt; 0</code></td>
<td>Positive, right-skewed data</td>
<td>Income, durations, reliability</td>
</tr>
<tr class="even">
<td><strong>Beta</strong></td>
<td>`beta_lpdf(y</td>
<td>α, β)`</td>
<td><code>α &gt; 0</code>, <code>β &gt; 0</code></td>
<td>Probabilities or proportions</td>
<td>Priors on probabilities (<code>θ ∈ (0, 1)</code>)</td>
</tr>
<tr class="odd">
<td><strong>Dirichlet</strong></td>
<td>`dirichlet_lpdf(θ</td>
<td>α)`</td>
<td><code>θ</code>: simplex, <code>α &gt; 0</code> vector</td>
<td>Probabilities summing to 1</td>
<td>Priors for category proportions, LDA</td>
</tr>
<tr class="even">
<td><strong>Poisson</strong></td>
<td>`poisson_lpmf(y</td>
<td>λ)`</td>
<td><code>λ &gt; 0</code></td>
<td>Count data, rare event modeling</td>
<td>GLMs for count data</td>
</tr>
<tr class="odd">
<td><strong>Negative Binomial</strong></td>
<td>`neg_binomial_2_lpmf(y</td>
<td>μ, φ)`</td>
<td><code>μ &gt; 0</code>, <code>φ &gt; 0</code></td>
<td>Overdispersed count data</td>
<td>GLMs with extra-Poisson variation</td>
</tr>
<tr class="even">
<td><strong>Ordered Logistic</strong></td>
<td>`ordered_logistic_lpmf(y</td>
<td>η, c)`</td>
<td><code>η ∈ ℝ</code>, <code>c</code>: ordered cut-points</td>
<td>Ordinal outcomes</td>
<td>Ordinal regression</td>
</tr>
<tr class="odd">
<td><strong>Uniform</strong></td>
<td>`uniform_lpdf(y</td>
<td>a, b)`</td>
<td><code>a &lt; b</code></td>
<td>Flat prior within range</td>
<td>Non-informative priors</td>
</tr>
<tr class="even">
<td><strong>Pareto</strong></td>
<td>`pareto_lpdf(y</td>
<td>y_min, α)`</td>
<td><code>y_min &gt; 0</code>, <code>α &gt; 0</code></td>
<td>Heavy-tail data, power-law phenomena</td>
<td>Extremes, outlier modeling</td>
</tr>
<tr class="odd">
<td><strong>Von Mises</strong></td>
<td>`von_mises_lpdf(y</td>
<td>μ, κ)`</td>
<td><code>μ ∈ [0, 2π)</code>, <code>κ ≥ 0</code></td>
<td>Circular data (angles, wind direction)</td>
<td>Directional models</td>
</tr>
<tr class="even">
<td><strong>Weibull</strong></td>
<td>`weibull_lpdf(y</td>
<td>α, σ)`</td>
<td><code>α, σ &gt; 0</code></td>
<td>Survival times, failure rates</td>
<td>Survival models, reliability analysis</td>
</tr>
<tr class="odd">
<td><strong>LKJ Correlation</strong></td>
<td>`lkj_corr_cholesky_lpdf(L</td>
<td>η)`</td>
<td><code>η &gt; 0</code>, <code>L</code>: Cholesky factor</td>
<td>Prior for correlation matrices</td>
<td>Hierarchical models with random slopes</td>
</tr>
<tr class="even">
<td><strong>Wishart</strong></td>
<td>`wishart_lpdf(S</td>
<td>ν, Σ)`</td>
<td><code>ν &gt; dim-1</code>, <code>Σ</code>: scale matrix</td>
<td>Prior on covariance matrices</td>
<td>Multivariate Gaussian models (rarely used)</td>
</tr>
</tbody>
</table>
</div>
<div id="main-stan-functions-cheatsheet" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Main Stan Functions Cheatsheet<a href="appendix.html#main-stan-functions-cheatsheet" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Stan is a robust platform for Bayesian statistical modeling, renowned for its Hamiltonian Monte Carlo (HMC) engine and flexible modeling language. While probability distributions like <code>normal_lpdf</code> or <code>poisson_lpmf</code> define priors and likelihoods, Stan’s non-distribution functions—spanning mathematical operations, matrix algebra, utility tools, and specialized solvers—are equally critical for building efficient and expressive models. These functions enable data transformations, efficient computations, and post-processing in the <code>generated quantities</code> block.</p>
<p>This cheatsheet organizes Stan’s most commonly used non-distribution functions into categories, providing their purpose, example usage, and the model types where they’re most applicable. Whether you’re crafting linear regressions, hierarchical models, or dynamic systems, this guide will help you leverage Stan’s toolkit effectively. We’ll wrap up with an example model to bring these functions to life.</p>
</div>
<div id="why-non-distribution-functions" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Why Non-Distribution Functions?<a href="appendix.html#why-non-distribution-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Stan’s non-distribution functions serve several key purposes:
- <strong>Transformations</strong>: Functions like <code>log</code>, <code>exp</code>, and <code>inv_logit</code> map parameters to constrained spaces or perform nonlinear calculations.
- <strong>Matrix Operations</strong>: Functions like <code>dot_product</code> and <code>cholesky_decompose</code> enable efficient linear algebra for multivariate models.
- <strong>Utilities</strong>: Functions like <code>to_vector</code> and <code>mean</code> simplify data manipulation and posterior summaries.
- <strong>Specialized Tools</strong>: Solvers like <code>ode_rk45</code> and <code>integrate_1d</code> tackle complex systems, such as differential equations or custom likelihoods.
- <strong>Posterior Processing</strong>: Functions in the <code>generated quantities</code> block, like <code>sum</code> or <code>sd</code>, compute diagnostics or predictions.</p>
<p>This cheatsheet focuses on these functions to help you streamline model specification and analysis.</p>
</div>
<div id="stan-functions-cheatsheet" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Stan Functions Cheatsheet<a href="appendix.html#stan-functions-cheatsheet" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="mathematical-functions" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> 1. Mathematical Functions<a href="appendix.html#mathematical-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These functions perform scalar operations, often used in <code>transformed parameters</code> or <code>model</code> blocks.</p>
<table>
<colgroup>
<col width="15%" />
<col width="27%" />
<col width="25%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Usage</strong></th>
<th><strong>Model Type(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>abs(x)</code></td>
<td>Absolute value</td>
<td><code>real z = abs(x);</code></td>
<td>General computations, robust stats</td>
</tr>
<tr class="even">
<td><code>exp(x)</code></td>
<td>Exponential (e^x)</td>
<td><code>lambda = exp(alpha);</code></td>
<td>Rate models, transformations</td>
</tr>
<tr class="odd">
<td><code>log(x)</code></td>
<td>Natural logarithm</td>
<td><code>real l = log(y);</code></td>
<td>Log-likelihoods, transformations</td>
</tr>
<tr class="even">
<td><code>sqrt(x)</code></td>
<td>Square root</td>
<td><code>sigma = sqrt(variance);</code></td>
<td>Variance computations, scaling</td>
</tr>
<tr class="odd">
<td><code>lgamma(x)</code></td>
<td>Log gamma function</td>
<td><code>lp += lgamma(alpha);</code></td>
<td>Mixture models, custom likelihoods</td>
</tr>
<tr class="even">
<td><code>log_sum_exp(x)</code></td>
<td>Log-sum-exp for numerical stability</td>
<td><code>lp = log_sum_exp(log_theta);</code></td>
<td>Mixture models, marginal likelihoods</td>
</tr>
</tbody>
</table>
</div>
<div id="transformation-functions" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> 2. Transformation Functions<a href="appendix.html#transformation-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These map parameters to constrained spaces, often in <code>transformed parameters</code>.</p>
<table>
<colgroup>
<col width="14%" />
<col width="26%" />
<col width="29%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Usage</strong></th>
<th><strong>Model Type(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>inv_logit(x)</code></td>
<td>Logistic sigmoid (ℝ → (0,1))</td>
<td><code>theta = inv_logit(alpha + beta*x);</code></td>
<td>Logistic regression, probability models</td>
</tr>
<tr class="even">
<td><code>logit(p)</code></td>
<td>Log-odds ((0,1) → ℝ)</td>
<td><code>eta = logit(p);</code></td>
<td>Logistic regression, probit models</td>
</tr>
<tr class="odd">
<td><code>softmax(x)</code></td>
<td>Normalize vector to simplex</td>
<td><code>theta = softmax(alpha);</code></td>
<td>Multinomial regression, LDA</td>
</tr>
<tr class="even">
<td><code>inv(x)</code></td>
<td>Reciprocal (1/x)</td>
<td><code>inv_sigma = inv(sigma);</code></td>
<td>Variance transformations</td>
</tr>
</tbody>
</table>
</div>
<div id="matrix-and-vector-operations" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> 3. Matrix and Vector Operations<a href="appendix.html#matrix-and-vector-operations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These enable efficient linear algebra, critical for multivariate and hierarchical models.</p>
<table>
<colgroup>
<col width="23%" />
<col width="25%" />
<col width="27%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Usage</strong></th>
<th><strong>Model Type(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>dot_product(a, b)</code></td>
<td>Inner product of two vectors</td>
<td><code>real z = dot_product(a, b);</code></td>
<td>Linear regression, similarity measures</td>
</tr>
<tr class="even">
<td><code>matrix_times_vector(A, v)</code></td>
<td>Matrix-vector multiplication</td>
<td><code>eta = matrix_times_vector(X, beta);</code></td>
<td>Multivariate regression, GLMs</td>
</tr>
<tr class="odd">
<td><code>cholesky_decompose(S)</code></td>
<td>Cholesky factorization</td>
<td><code>L = cholesky_decompose(Sigma);</code></td>
<td>Hierarchical models, multivariate normals</td>
</tr>
<tr class="even">
<td><code>multiply_lower_tri_self_transpose(L)</code></td>
<td>Covariance from Cholesky factor</td>
<td><code>Sigma = multiply_lower_tri_self_transpose(L);</code></td>
<td>Multivariate normals, hierarchical models</td>
</tr>
<tr class="odd">
<td><code>diag_matrix(v)</code></td>
<td>Diagonal matrix from vector</td>
<td><code>M = diag_matrix(v);</code></td>
<td>Covariance priors, scaling</td>
</tr>
<tr class="even">
<td><code>determinant(A)</code></td>
<td>Matrix determinant</td>
<td><code>det = determinant(Sigma);</code></td>
<td>Model diagnostics, multivariate priors</td>
</tr>
</tbody>
</table>
</div>
<div id="utility-functions" class="section level3 hasAnchor" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> 4. Utility Functions<a href="appendix.html#utility-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These simplify data manipulation and posterior summaries, often in <code>generated quantities</code>.</p>
<table>
<colgroup>
<col width="15%" />
<col width="27%" />
<col width="24%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Usage</strong></th>
<th><strong>Model Type(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>to_vector(x)</code></td>
<td>Convert matrix/array to vector</td>
<td><code>vec = to_vector(matrix);</code></td>
<td>Posterior summaries, data reshaping</td>
</tr>
<tr class="even">
<td><code>to_array_1d(x)</code></td>
<td>Convert to 1D array</td>
<td><code>arr = to_array_1d(matrix);</code></td>
<td>Data preprocessing, summaries</td>
</tr>
<tr class="odd">
<td><code>sum(x)</code></td>
<td>Sum of elements</td>
<td><code>total = sum(y);</code></td>
<td>Aggregations, diagnostics</td>
</tr>
<tr class="even">
<td><code>mean(x)</code></td>
<td>Mean of elements</td>
<td><code>avg = mean(y_rep);</code></td>
<td>Posterior summaries, diagnostics</td>
</tr>
<tr class="odd">
<td><code>sd(x)</code></td>
<td>Standard deviation</td>
<td><code>std = sd(y_rep);</code></td>
<td>Posterior summaries, diagnostics</td>
</tr>
<tr class="even">
<td><code>int_step(x)</code></td>
<td>Indicator (x ≥ 0 → 1, else 0)</td>
<td><code>flag = int_step(x - 1);</code></td>
<td>Conditional logic, model diagnostics</td>
</tr>
</tbody>
</table>
</div>
<div id="specialized-solvers" class="section level3 hasAnchor" number="6.4.5">
<h3><span class="header-section-number">6.4.5</span> 5. Specialized Solvers<a href="appendix.html#specialized-solvers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These handle advanced computations like differential equations or parallel processing.</p>
<table>
<colgroup>
<col width="21%" />
<col width="24%" />
<col width="28%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Usage</strong></th>
<th><strong>Model Type(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>ode_rk45(fun, y0, t0, ts, ...)</code></td>
<td>Solve ODEs (Runge-Kutta 45)</td>
<td><code>y = ode_rk45(ode_sys, y0, t0, ts, params);</code></td>
<td>Dynamic systems, pharmacokinetics</td>
</tr>
<tr class="even">
<td><code>integrate_1d(f, a, b, ...)</code></td>
<td>Numerical integration</td>
<td><code>val = integrate_1d(f, a, b, params);</code></td>
<td>Custom likelihoods, marginalization</td>
</tr>
<tr class="odd">
<td><code>map_rect(f, phi, ...)</code></td>
<td>Parallel computation over data shards</td>
<td><code>results = map_rect(f, phi, theta, data);</code></td>
<td>Large-scale hierarchical models</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="example-hierarchical-linear-regression" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Example: Hierarchical Linear Regression<a href="appendix.html#example-hierarchical-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here’s a Stan model for a hierarchical linear regression, using <code>matrix_times_vector</code>, <code>to_vector</code>, and <code>mean</code> to demonstrate practical function usage:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb74-1"><a href="appendix.html#cb74-1" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb74-2"><a href="appendix.html#cb74-2" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N; <span class="co">// Number of observations</span></span>
<span id="cb74-3"><a href="appendix.html#cb74-3" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; J; <span class="co">// Number of groups</span></span>
<span id="cb74-4"><a href="appendix.html#cb74-4" tabindex="-1"></a>  <span class="dt">array</span>[N] <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=J&gt; group; <span class="co">// Group indicators</span></span>
<span id="cb74-5"><a href="appendix.html#cb74-5" tabindex="-1"></a>  <span class="dt">matrix</span>[N, <span class="dv">2</span>] X; <span class="co">// Design matrix (intercept + predictor)</span></span>
<span id="cb74-6"><a href="appendix.html#cb74-6" tabindex="-1"></a>  <span class="dt">vector</span>[N] y; <span class="co">// Outcome</span></span>
<span id="cb74-7"><a href="appendix.html#cb74-7" tabindex="-1"></a>}</span>
<span id="cb74-8"><a href="appendix.html#cb74-8" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb74-9"><a href="appendix.html#cb74-9" tabindex="-1"></a>  <span class="dt">vector</span>[<span class="dv">2</span>] beta; <span class="co">// Fixed effects</span></span>
<span id="cb74-10"><a href="appendix.html#cb74-10" tabindex="-1"></a>  <span class="dt">vector</span>[J] alpha; <span class="co">// Group-level intercepts</span></span>
<span id="cb74-11"><a href="appendix.html#cb74-11" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma; <span class="co">// Residual standard deviation</span></span>
<span id="cb74-12"><a href="appendix.html#cb74-12" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; tau; <span class="co">// Standard deviation of group intercepts</span></span>
<span id="cb74-13"><a href="appendix.html#cb74-13" tabindex="-1"></a>}</span>
<span id="cb74-14"><a href="appendix.html#cb74-14" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb74-15"><a href="appendix.html#cb74-15" tabindex="-1"></a>  beta ~ normal(<span class="dv">0</span>, <span class="dv">5</span>); <span class="co">// Prior on fixed effects</span></span>
<span id="cb74-16"><a href="appendix.html#cb74-16" tabindex="-1"></a>  tau ~ cauchy(<span class="dv">0</span>, <span class="fl">2.5</span>); <span class="co">// Prior on group SD</span></span>
<span id="cb74-17"><a href="appendix.html#cb74-17" tabindex="-1"></a>  alpha ~ normal(<span class="dv">0</span>, tau); <span class="co">// Group-level priors</span></span>
<span id="cb74-18"><a href="appendix.html#cb74-18" tabindex="-1"></a>  sigma ~ cauchy(<span class="dv">0</span>, <span class="fl">2.5</span>); <span class="co">// Prior on residual SD</span></span>
<span id="cb74-19"><a href="appendix.html#cb74-19" tabindex="-1"></a>  <span class="dt">vector</span>[N] mu = matrix_times_vector(X, beta) + to_vector(alpha[group]);</span>
<span id="cb74-20"><a href="appendix.html#cb74-20" tabindex="-1"></a>  y ~ normal(mu, sigma); <span class="co">// Likelihood</span></span>
<span id="cb74-21"><a href="appendix.html#cb74-21" tabindex="-1"></a>}</span>
<span id="cb74-22"><a href="appendix.html#cb74-22" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb74-23"><a href="appendix.html#cb74-23" tabindex="-1"></a>  <span class="dt">vector</span>[N] y_rep; <span class="co">// Posterior predictive</span></span>
<span id="cb74-24"><a href="appendix.html#cb74-24" tabindex="-1"></a>  <span class="dt">real</span> mean_y_rep; <span class="co">// Mean of predictions</span></span>
<span id="cb74-25"><a href="appendix.html#cb74-25" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb74-26"><a href="appendix.html#cb74-26" tabindex="-1"></a>    y_rep[n] = normal_rng(matrix_times_vector(X[n], beta) + alpha[group[n]], sigma);</span>
<span id="cb74-27"><a href="appendix.html#cb74-27" tabindex="-1"></a>  }</span>
<span id="cb74-28"><a href="appendix.html#cb74-28" tabindex="-1"></a>  mean_y_rep = mean(to_vector(y_rep)); <span class="co">// Summary statistic</span></span>
<span id="cb74-29"><a href="appendix.html#cb74-29" tabindex="-1"></a>}</span></code></pre></div>
<p>This model:
- Uses <code>matrix_times_vector</code> to compute the linear predictor efficiently.
- Employs <code>to_vector</code> to align group-level intercepts with observations.
- Computes <code>mean_y_rep</code> in <code>generated quantities</code> using <code>mean</code> and <code>to_vector</code> for posterior diagnostics.
- Generates predictions with <code>normal_rng</code> for posterior predictive checks.</p>
</div>
<div id="tips-for-using-stan-functions" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Tips for Using Stan Functions<a href="appendix.html#tips-for-using-stan-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><strong>Efficiency</strong>: Prefer vectorized operations like <code>matrix_times_vector</code> over loops for speed.</li>
<li><strong>Numerical Stability</strong>: Use <code>log_sum_exp</code> for summing exponentials to avoid overflow.</li>
<li><strong>Posterior Analysis</strong>: Leverage <code>mean</code>, <code>sd</code>, and <code>to_vector</code> in <code>generated quantities</code> for summaries and diagnostics.</li>
<li><strong>Constraints</strong>: Ensure inputs meet requirements (e.g., <code>x &gt; 0</code> for <code>log</code>, positive-definite matrices for <code>cholesky_decompose</code>).</li>
<li><strong>Advanced Modeling</strong>: Use <code>ode_rk45</code> for dynamic systems or <code>map_rect</code> for parallelized large-scale models.</li>
<li><strong>Documentation</strong>: The <a href="https://mc-stan.org/docs/">Stan Reference Manual</a> (e.g., version 2.33) and Stan’s GitHub examples provide detailed guidance.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-regularized-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_Stan/edit/main/Appendix.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_Stan/blob/main/Appendix.Rmd",
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

</body>

</html>
